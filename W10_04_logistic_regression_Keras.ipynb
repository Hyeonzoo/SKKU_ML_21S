{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list 생성 후 연산을 위해 np.array로 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [[1,1],[1,3],[2,2],[2,4],[3,1],[3,3],[4,2],[4,4],[5,7],[5,9],[6,6],[6,8],[7,7],[7,9],[8,6],[8,8]]\n",
    "train_y = [[0],[0],[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1],[1],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list를 연산하려 할 때 생기는 오류\n",
    "# list indices must be integers or slices, not tuple\n",
    "#plt.scatter(train_x[:,0:1], train_x[:,1:2], c=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 3],\n",
       "       [2, 2],\n",
       "       [2, 4],\n",
       "       [3, 1],\n",
       "       [3, 3],\n",
       "       [4, 2],\n",
       "       [4, 4],\n",
       "       [5, 7],\n",
       "       [5, 9],\n",
       "       [6, 6],\n",
       "       [6, 8],\n",
       "       [7, 7],\n",
       "       [7, 9],\n",
       "       [8, 6],\n",
       "       [8, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 시각화 (산점도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 시각화해서 보기 위해 matplotlib.pyplot 모듈의 scatter()함수 (산점도) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_x[:,0:1], train_x[:,1:2], c=train_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**scatter(x, y, size =, color =, alpha = , label = )**\n",
    "\n",
    "train_x의 모든 list의 0번째 array를 x값으로, 1번째 array를 y값으로 사용하여 그래프 생성  \n",
    "c(color)는 train_y의 그룹에 맞게 같은 그룹끼리 같은 색으로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras를 이용한 Logistic Regression 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keras를 이용한 class 생성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras : tensorflow 확장 라이브러리 중 하나  \n",
    " - 순차형(Sequential) 모델 : 계층(layer)을 쌓아 모델링 하도록 설계\n",
    " - 함수형 API (Funtional API) : 다양한 계층 구조를 가진 일반적인 모델 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticWithKeras():\n",
    "    # 초기화(initialize) 메소드 : 객체 생성시 자동으로 호출되는 메소드\n",
    "    def __init__(self):\n",
    "        self.epochs = 500\n",
    "        self.learning_rate = 0.17\n",
    "\n",
    "    # layer를 기준으로 모델을 정의\n",
    "    def buildModel(self):\n",
    "        # 순차형(Sequential) 모델 사용\n",
    "        self.model = tf.keras.Sequential() \n",
    "        \n",
    "        # 1개의 unit을 가진 Fully-Connected layer층 모델에 추가\n",
    "        # 활성화 함수는 sigmoid 사용\n",
    "        self.model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        # 확률적 경사 하강법(Stochastic Gradient Descent, SGD) 옵티마이저\n",
    "        optimizer = tf.keras.optimizers.SGD(self.learning_rate)\n",
    "\n",
    "        self.model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['binary_accuracy'])\n",
    "\n",
    "    # train_x, train_y를 가지고 model을 학습하는 메소드    \n",
    "    def fitModel(self, x, y):\n",
    "        # shuffle 파라미터가 true이면 각 epoch마다 새로운 order를 만들어냄 (데이터셋을 무작위로 섞음)\n",
    "        self.model.fit(x, y, epochs=self.epochs, batch_size=8, shuffle=True)\n",
    "\n",
    "    # train_x를 가지고 학습된 model의 결과에 적용해서 label을 도출하는 메소드\n",
    "    def predictModel(self, x):\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    # test_x, test_y를 가지고 학습된 model에 적용해서 res_y를 구하고, 이를 test_y와 비교한 정학도를 도출\n",
    "    def evalModel(self, x, y):\n",
    "        return self.model.evaluate(x,y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**학습에 따른 loss 값 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 0s 582us/step - loss: 0.8833 - binary_accuracy: 0.5000\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 395us/step - loss: 0.6447 - binary_accuracy: 0.5625\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 466us/step - loss: 0.6083 - binary_accuracy: 0.5625\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 464us/step - loss: 0.5656 - binary_accuracy: 0.6875\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 479us/step - loss: 0.5525 - binary_accuracy: 0.6875\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 354us/step - loss: 0.5488 - binary_accuracy: 0.6875\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 388us/step - loss: 0.5270 - binary_accuracy: 0.8125\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 318us/step - loss: 0.5188 - binary_accuracy: 0.6875\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.6016 - binary_accuracy: 0.6875\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 335us/step - loss: 0.6900 - binary_accuracy: 0.6875\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 364us/step - loss: 0.7652 - binary_accuracy: 0.6250\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 362us/step - loss: 0.5258 - binary_accuracy: 0.7500\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.6395 - binary_accuracy: 0.6250\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.4531 - binary_accuracy: 0.8125\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.4730 - binary_accuracy: 0.6875\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.4618 - binary_accuracy: 0.8125\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.4976 - binary_accuracy: 0.6875\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.4963 - binary_accuracy: 0.7500\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.4912 - binary_accuracy: 0.8125\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.5159 - binary_accuracy: 0.6875\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.5253 - binary_accuracy: 0.6250\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 341us/step - loss: 0.5183 - binary_accuracy: 0.7500\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 387us/step - loss: 0.5155 - binary_accuracy: 0.7500\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 318us/step - loss: 0.5103 - binary_accuracy: 0.6875\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.4432 - binary_accuracy: 0.8125\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.5174 - binary_accuracy: 0.7500\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.4125 - binary_accuracy: 0.8750\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 319us/step - loss: 0.5241 - binary_accuracy: 0.6875\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.3875 - binary_accuracy: 0.8125\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.4071 - binary_accuracy: 0.7500\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.4377 - binary_accuracy: 0.7500\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.3302 - binary_accuracy: 0.8750\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 318us/step - loss: 0.3460 - binary_accuracy: 0.9375\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 322us/step - loss: 0.3359 - binary_accuracy: 0.8125\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.3213 - binary_accuracy: 0.9375\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 381us/step - loss: 0.3256 - binary_accuracy: 0.8750\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.3637 - binary_accuracy: 0.8750\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 295us/step - loss: 0.4634 - binary_accuracy: 0.7500\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - 0s 322us/step - loss: 0.3634 - binary_accuracy: 0.8125\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.3231 - binary_accuracy: 0.9375\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 319us/step - loss: 0.2962 - binary_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.3499 - binary_accuracy: 0.8750\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.3323 - binary_accuracy: 0.8125\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.2958 - binary_accuracy: 0.8750\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.3453 - binary_accuracy: 0.8750\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.3060 - binary_accuracy: 0.9375\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.4478 - binary_accuracy: 0.8125\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.3397 - binary_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.3852 - binary_accuracy: 0.8125\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.2880 - binary_accuracy: 0.9375\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 302us/step - loss: 0.3313 - binary_accuracy: 0.8750\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.3281 - binary_accuracy: 0.8125\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.2659 - binary_accuracy: 0.9375\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 320us/step - loss: 0.2724 - binary_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.3203 - binary_accuracy: 0.9375\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.3166 - binary_accuracy: 0.9375\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.2587 - binary_accuracy: 0.8750\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.2492 - binary_accuracy: 0.9375\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.2730 - binary_accuracy: 1.0000\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.2638 - binary_accuracy: 0.9375\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.2320 - binary_accuracy: 1.0000\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.2380 - binary_accuracy: 1.0000\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 296us/step - loss: 0.2341 - binary_accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.2258 - binary_accuracy: 0.9375\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 481us/step - loss: 0.2584 - binary_accuracy: 1.0000\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.2419 - binary_accuracy: 0.9375\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.2316 - binary_accuracy: 1.0000\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.2330 - binary_accuracy: 0.9375\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.2178 - binary_accuracy: 1.0000\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.2218 - binary_accuracy: 0.9375\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 306us/step - loss: 0.2224 - binary_accuracy: 1.0000\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.2816 - binary_accuracy: 0.9375\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.2265 - binary_accuracy: 1.0000\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.2100 - binary_accuracy: 1.0000\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.2133 - binary_accuracy: 1.0000\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.2060 - binary_accuracy: 0.9375\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 306us/step - loss: 0.2074 - binary_accuracy: 1.0000\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.2096 - binary_accuracy: 0.9375\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.2010 - binary_accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 306us/step - loss: 0.1976 - binary_accuracy: 1.0000\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.2000 - binary_accuracy: 1.0000\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.1967 - binary_accuracy: 0.9375\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.1921 - binary_accuracy: 1.0000\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.1922 - binary_accuracy: 1.0000\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 306us/step - loss: 0.1952 - binary_accuracy: 0.9375\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.2345 - binary_accuracy: 0.9375\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.1901 - binary_accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.1870 - binary_accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.2199 - binary_accuracy: 1.0000\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.1960 - binary_accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.1826 - binary_accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.1805 - binary_accuracy: 1.0000\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.1955 - binary_accuracy: 0.9375\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.1785 - binary_accuracy: 1.0000\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1797 - binary_accuracy: 1.0000\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.1812 - binary_accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.1787 - binary_accuracy: 0.9375\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 312us/step - loss: 0.1732 - binary_accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 319us/step - loss: 0.1730 - binary_accuracy: 1.0000\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 318us/step - loss: 0.1746 - binary_accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.1724 - binary_accuracy: 1.0000\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.1683 - binary_accuracy: 1.0000\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 337us/step - loss: 0.1675 - binary_accuracy: 1.0000\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 336us/step - loss: 0.1677 - binary_accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.1785 - binary_accuracy: 1.0000\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 312us/step - loss: 0.1664 - binary_accuracy: 0.9375\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.1646 - binary_accuracy: 1.0000\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.1800 - binary_accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1677 - binary_accuracy: 1.0000\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.1602 - binary_accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.1668 - binary_accuracy: 1.0000\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1629 - binary_accuracy: 1.0000\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.1663 - binary_accuracy: 1.0000\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.1618 - binary_accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1577 - binary_accuracy: 1.0000\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.1701 - binary_accuracy: 1.0000\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 315us/step - loss: 0.1715 - binary_accuracy: 1.0000\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1572 - binary_accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.1591 - binary_accuracy: 1.0000\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 340us/step - loss: 0.1526 - binary_accuracy: 1.0000\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.1498 - binary_accuracy: 1.0000\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 319us/step - loss: 0.1559 - binary_accuracy: 1.0000\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 306us/step - loss: 0.1596 - binary_accuracy: 1.0000\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 360us/step - loss: 0.1861 - binary_accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 351us/step - loss: 0.1772 - binary_accuracy: 0.9375\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 358us/step - loss: 0.1506 - binary_accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 358us/step - loss: 0.1744 - binary_accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.1563 - binary_accuracy: 0.9375\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.1450 - binary_accuracy: 1.0000\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 353us/step - loss: 0.1617 - binary_accuracy: 1.0000\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 369us/step - loss: 0.1488 - binary_accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.1422 - binary_accuracy: 1.0000\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 352us/step - loss: 0.1446 - binary_accuracy: 1.0000\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.1463 - binary_accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 332us/step - loss: 0.1520 - binary_accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 373us/step - loss: 0.1397 - binary_accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 320us/step - loss: 0.1374 - binary_accuracy: 1.0000\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 315us/step - loss: 0.1400 - binary_accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.1372 - binary_accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 322us/step - loss: 0.1371 - binary_accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 315us/step - loss: 0.1391 - binary_accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.1406 - binary_accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - 0s 360us/step - loss: 0.1419 - binary_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.1423 - binary_accuracy: 1.0000\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.1426 - binary_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 353us/step - loss: 0.1560 - binary_accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.1392 - binary_accuracy: 0.9375\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 322us/step - loss: 0.1312 - binary_accuracy: 1.0000\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.1346 - binary_accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.1337 - binary_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 316us/step - loss: 0.1407 - binary_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.1344 - binary_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.1277 - binary_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.1271 - binary_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 316us/step - loss: 0.1310 - binary_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1263 - binary_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.1289 - binary_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.1288 - binary_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.1299 - binary_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 315us/step - loss: 0.1246 - binary_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 318us/step - loss: 0.1267 - binary_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 316us/step - loss: 0.1242 - binary_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.1407 - binary_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 322us/step - loss: 0.1430 - binary_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.1271 - binary_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.1215 - binary_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.1200 - binary_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.1238 - binary_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.1214 - binary_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.1206 - binary_accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 318us/step - loss: 0.1220 - binary_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1217 - binary_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 354us/step - loss: 0.1169 - binary_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 343us/step - loss: 0.1166 - binary_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.1186 - binary_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 358us/step - loss: 0.1382 - binary_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.1197 - binary_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 301us/step - loss: 0.1152 - binary_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.1161 - binary_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.1145 - binary_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.1130 - binary_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.1130 - binary_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.1123 - binary_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.1126 - binary_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.1114 - binary_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.1318 - binary_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.1137 - binary_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1105 - binary_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 319us/step - loss: 0.1116 - binary_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.1095 - binary_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.1200 - binary_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.1151 - binary_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 333us/step - loss: 0.1120 - binary_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.1081 - binary_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 363us/step - loss: 0.1075 - binary_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.1166 - binary_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 318us/step - loss: 0.1072 - binary_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 320us/step - loss: 0.1180 - binary_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1102 - binary_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.1185 - binary_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1199 - binary_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 320us/step - loss: 0.1154 - binary_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 340us/step - loss: 0.1085 - binary_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.1076 - binary_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 342us/step - loss: 0.1220 - binary_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 360us/step - loss: 0.1204 - binary_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 315us/step - loss: 0.1052 - binary_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.1042 - binary_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 318us/step - loss: 0.1028 - binary_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.1074 - binary_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.1019 - binary_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.1204 - binary_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1036 - binary_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.1075 - binary_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.1015 - binary_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 316us/step - loss: 0.1056 - binary_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.1035 - binary_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.1017 - binary_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.0989 - binary_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.1042 - binary_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.0983 - binary_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.0990 - binary_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 355us/step - loss: 0.1140 - binary_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.1055 - binary_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 306us/step - loss: 0.0985 - binary_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 336us/step - loss: 0.0984 - binary_accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 315us/step - loss: 0.0999 - binary_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 319us/step - loss: 0.0958 - binary_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 315us/step - loss: 0.0953 - binary_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.1012 - binary_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.0954 - binary_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 315us/step - loss: 0.1018 - binary_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 316us/step - loss: 0.0951 - binary_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.0989 - binary_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.0974 - binary_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 343us/step - loss: 0.0943 - binary_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.1048 - binary_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.0978 - binary_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.1005 - binary_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.0962 - binary_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0926 - binary_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 336us/step - loss: 0.0920 - binary_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 336us/step - loss: 0.0935 - binary_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.1017 - binary_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.0921 - binary_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.0931 - binary_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 332us/step - loss: 0.0913 - binary_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 339us/step - loss: 0.0908 - binary_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0899 - binary_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 337us/step - loss: 0.0945 - binary_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0940 - binary_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0896 - binary_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0939 - binary_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 342us/step - loss: 0.0900 - binary_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 351us/step - loss: 0.0884 - binary_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0888 - binary_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.0915 - binary_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.0906 - binary_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.1022 - binary_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0959 - binary_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0966 - binary_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - 0s 303us/step - loss: 0.0866 - binary_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 337us/step - loss: 0.0867 - binary_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 334us/step - loss: 0.0879 - binary_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.1017 - binary_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.0879 - binary_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 345us/step - loss: 0.0909 - binary_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.0856 - binary_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 300us/step - loss: 0.0888 - binary_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 332us/step - loss: 0.0850 - binary_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.0846 - binary_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 338us/step - loss: 0.0869 - binary_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0884 - binary_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0864 - binary_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 300us/step - loss: 0.0881 - binary_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 301us/step - loss: 0.0894 - binary_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0844 - binary_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0871 - binary_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0844 - binary_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 334us/step - loss: 0.0852 - binary_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0834 - binary_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 301us/step - loss: 0.0821 - binary_accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0842 - binary_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 300us/step - loss: 0.0921 - binary_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.0822 - binary_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0810 - binary_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0810 - binary_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.0845 - binary_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.0830 - binary_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.0887 - binary_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 333us/step - loss: 0.0856 - binary_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 335us/step - loss: 0.0814 - binary_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.0888 - binary_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.0806 - binary_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0793 - binary_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 343us/step - loss: 0.0794 - binary_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.0824 - binary_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 342us/step - loss: 0.0788 - binary_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0821 - binary_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.0905 - binary_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 340us/step - loss: 0.0835 - binary_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 335us/step - loss: 0.0827 - binary_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 312us/step - loss: 0.0787 - binary_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.0776 - binary_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.0853 - binary_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 335us/step - loss: 0.0816 - binary_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0788 - binary_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 302us/step - loss: 0.0868 - binary_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.0793 - binary_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0769 - binary_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 334us/step - loss: 0.0818 - binary_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 332us/step - loss: 0.0809 - binary_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 324us/step - loss: 0.0766 - binary_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0770 - binary_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 338us/step - loss: 0.0775 - binary_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0769 - binary_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0831 - binary_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0873 - binary_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0813 - binary_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0791 - binary_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.0746 - binary_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0751 - binary_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 341us/step - loss: 0.0834 - binary_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.0772 - binary_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0782 - binary_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0745 - binary_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0739 - binary_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 326us/step - loss: 0.0791 - binary_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0767 - binary_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 332us/step - loss: 0.0755 - binary_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 333us/step - loss: 0.0735 - binary_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 333us/step - loss: 0.0805 - binary_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 349us/step - loss: 0.0733 - binary_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.0731 - binary_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 343us/step - loss: 0.0741 - binary_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 303us/step - loss: 0.0726 - binary_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 374us/step - loss: 0.0737 - binary_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0718 - binary_accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 303us/step - loss: 0.0715 - binary_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0713 - binary_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 301us/step - loss: 0.0735 - binary_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.0719 - binary_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 337us/step - loss: 0.0712 - binary_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0732 - binary_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0750 - binary_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 336us/step - loss: 0.0709 - binary_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 298us/step - loss: 0.0712 - binary_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0773 - binary_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.0701 - binary_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0699 - binary_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.0755 - binary_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.0781 - binary_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.0775 - binary_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 350us/step - loss: 0.0741 - binary_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.0867 - binary_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 350us/step - loss: 0.0718 - binary_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0758 - binary_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0699 - binary_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 337us/step - loss: 0.0730 - binary_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 351us/step - loss: 0.0744 - binary_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 350us/step - loss: 0.0703 - binary_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 286us/step - loss: 0.0714 - binary_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 298us/step - loss: 0.0695 - binary_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 340us/step - loss: 0.0679 - binary_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.0717 - binary_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 338us/step - loss: 0.0678 - binary_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 342us/step - loss: 0.0685 - binary_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 342us/step - loss: 0.0676 - binary_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 349us/step - loss: 0.0672 - binary_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0763 - binary_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0727 - binary_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.0691 - binary_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 332us/step - loss: 0.0709 - binary_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 312us/step - loss: 0.0687 - binary_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.0674 - binary_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 310us/step - loss: 0.0668 - binary_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0669 - binary_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0660 - binary_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 298us/step - loss: 0.0769 - binary_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.0671 - binary_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0693 - binary_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0659 - binary_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0692 - binary_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0736 - binary_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.0658 - binary_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.0653 - binary_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 341us/step - loss: 0.0653 - binary_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.0685 - binary_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.0673 - binary_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 332us/step - loss: 0.0720 - binary_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0644 - binary_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 306us/step - loss: 0.0708 - binary_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.0644 - binary_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0648 - binary_accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 337us/step - loss: 0.0643 - binary_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0638 - binary_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 336us/step - loss: 0.0649 - binary_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.0637 - binary_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0646 - binary_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 347us/step - loss: 0.0636 - binary_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 302us/step - loss: 0.0632 - binary_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 303us/step - loss: 0.0642 - binary_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0631 - binary_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.0637 - binary_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 334us/step - loss: 0.0628 - binary_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 346us/step - loss: 0.0650 - binary_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0648 - binary_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 347us/step - loss: 0.0649 - binary_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 350us/step - loss: 0.0626 - binary_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 349us/step - loss: 0.0635 - binary_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 343us/step - loss: 0.0634 - binary_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0654 - binary_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0619 - binary_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 321us/step - loss: 0.0617 - binary_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 301us/step - loss: 0.0635 - binary_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 352us/step - loss: 0.0627 - binary_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 301us/step - loss: 0.0668 - binary_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 347us/step - loss: 0.0633 - binary_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0654 - binary_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0628 - binary_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 300us/step - loss: 0.0633 - binary_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 348us/step - loss: 0.0611 - binary_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 347us/step - loss: 0.0636 - binary_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 302us/step - loss: 0.0669 - binary_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 289us/step - loss: 0.0629 - binary_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 349us/step - loss: 0.0616 - binary_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 302us/step - loss: 0.0668 - binary_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 343us/step - loss: 0.0611 - binary_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 313us/step - loss: 0.0616 - binary_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 334us/step - loss: 0.0601 - binary_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 342us/step - loss: 0.0599 - binary_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 334us/step - loss: 0.0636 - binary_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0652 - binary_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0630 - binary_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 333us/step - loss: 0.0596 - binary_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 345us/step - loss: 0.0595 - binary_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0619 - binary_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0601 - binary_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0597 - binary_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0636 - binary_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0591 - binary_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0618 - binary_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0590 - binary_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0587 - binary_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 347us/step - loss: 0.0601 - binary_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 345us/step - loss: 0.0586 - binary_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0631 - binary_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0585 - binary_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 347us/step - loss: 0.0593 - binary_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 334us/step - loss: 0.0580 - binary_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.0629 - binary_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0582 - binary_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.0635 - binary_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 344us/step - loss: 0.0632 - binary_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 302us/step - loss: 0.0606 - binary_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 299us/step - loss: 0.0601 - binary_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0579 - binary_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 309us/step - loss: 0.0575 - binary_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 342us/step - loss: 0.0572 - binary_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 298us/step - loss: 0.0577 - binary_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 341us/step - loss: 0.0589 - binary_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0590 - binary_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 329us/step - loss: 0.0607 - binary_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.0576 - binary_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.0578 - binary_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.0598 - binary_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 305us/step - loss: 0.0597 - binary_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 319us/step - loss: 0.0596 - binary_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 301us/step - loss: 0.0565 - binary_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 300us/step - loss: 0.0578 - binary_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 306us/step - loss: 0.0561 - binary_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 349us/step - loss: 0.0562 - binary_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 327us/step - loss: 0.0588 - binary_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0640 - binary_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0601 - binary_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 343us/step - loss: 0.0560 - binary_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 345us/step - loss: 0.0558 - binary_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 320us/step - loss: 0.0558 - binary_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 312us/step - loss: 0.0623 - binary_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - 0s 317us/step - loss: 0.0561 - binary_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0589 - binary_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 331us/step - loss: 0.0572 - binary_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.0630 - binary_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 332us/step - loss: 0.0553 - binary_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 308us/step - loss: 0.0563 - binary_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0563 - binary_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0564 - binary_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 360us/step - loss: 0.0575 - binary_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 303us/step - loss: 0.0558 - binary_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0592 - binary_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 304us/step - loss: 0.0548 - binary_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 330us/step - loss: 0.0554 - binary_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 302us/step - loss: 0.0568 - binary_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 325us/step - loss: 0.0545 - binary_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 323us/step - loss: 0.0543 - binary_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 307us/step - loss: 0.0552 - binary_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 328us/step - loss: 0.0543 - binary_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 371us/step - loss: 0.0540 - binary_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 311us/step - loss: 0.0550 - binary_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 314us/step - loss: 0.0539 - binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = LogisticWithKeras()\n",
    "model.buildModel()\n",
    "model.fitModel(train_x, train_y) # train_x와 train_y 데이터로 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_x를 model에 적용하여 결과 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res_y = model.predictModel(train_x)\n",
    "plt.scatter(train_x[:,0:1], train_x[:,1:2], c=res_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] [0.00300425] - [0]\n",
      "[1 3] [0.02208179] - [0]\n",
      "[2 2] [0.01424909] - [0]\n",
      "[2 4] [0.0977338] - [0]\n",
      "[3 1] [0.00916871] - [0]\n",
      "[3 3] [0.06484592] - [0]\n",
      "[4 2] [0.04250357] - [0]\n",
      "[4 4] [0.24961135] - [0]\n",
      "[5 7] [0.9228256] - [1]\n",
      "[5 9] [0.9889631] - [1]\n",
      "[6 6] [0.8844576] - [1]\n",
      "[6 8] [0.9828656] - [1]\n",
      "[7 7] [0.9734895] - [1]\n",
      "[7 9] [0.996379] - [1]\n",
      "[8 6] [0.95919585] - [1]\n",
      "[8 8] [0.99435514] - [1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, train_x.shape[0]):\n",
    "    print(train_x[i], res_y[i], \"-\", train_y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_x를 model에 적용한 결과 res_y의 label은   \n",
    "train_y에서 label 0이었던 값들은 0에 가깝게,\n",
    "train_y에서 label이 1이었던 값들은 1에 가까운 값이 나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**정확도 결과**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [[2,3],[3,2],[6,9],[7,8],[8,7]]\n",
    "test_y = [[0],[0],[1],[1],[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.array(test_x, dtype=np.float32)\n",
    "test_y = np.array(test_y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 463us/step - loss: 0.0191 - binary_accuracy: 1.0000\n",
      "[0.019098099321126938, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(model.evalModel(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(test_x[:,0:1], test_x[:,1:2], c=test_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* accuracy가 1.0으로 완벽하게 학습  \n",
    "* test 데이터에 대해서도 정확하게 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* https://ayoteralab.tistory.com/entry/Logistic-Regression-Tutorial-with-Numpy-Tensorflow-Keras  \n",
    "* https://excelsior-cjh.tistory.com/159"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
